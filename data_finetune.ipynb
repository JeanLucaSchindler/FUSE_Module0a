{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from make_data import load_dict_from_json\n",
    "from tools import *\n",
    "import json\n",
    "import os\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=os.environ.get(\"FUSE_OPEN_AI_KEY\"))\n",
    "\n",
    "import time\n",
    "\n",
    "import json\n",
    "import tiktoken # for token counting\n",
    "import numpy as np\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "database = load_dict_from_json('data/M0A_train_data.json')\n",
    "test_sample = select_random_keys(database, 1000, 45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "themes = {\n",
    "'Conscience': 'T1',\n",
    "'Desire': 'T2',\n",
    "'Freedom': 'T3',\n",
    "'Goodness': 'T4',\n",
    "'Identity': 'T5',\n",
    "'Justice': 'T6',\n",
    "'Language': 'T7',\n",
    "'Meaning': 'T8',\n",
    "'Science': 'T9',\n",
    "'Technology': 'T10',\n",
    "'Truth': 'T11',\n",
    "'Time': 'T12',\n",
    "'Existence': 'T13',\n",
    "'Music': 'T14',\n",
    "'Imagination': 'T15',\n",
    "'The Unconscious': 'T16',\n",
    "'Education': 'T17',\n",
    "'Body & Mind': 'T18',\n",
    "'Beauty': 'T19',\n",
    "'Art': 'T20',\n",
    "'Love': 'T21',\n",
    "'Reality': 'T22',\n",
    "'Politics': 'T23',\n",
    "'Work': 'T24',\n",
    "'Living Together': 'T25',\n",
    "'Philosophy': 'T26',\n",
    "'Matter': 'T27',\n",
    "'Death': 'T28',\n",
    "'Religion': 'T29',\n",
    "'History': 'T30',\n",
    "'Thought': 'T31',\n",
    "'Madness': 'T32',\n",
    "'Joy & Happiness': 'T33'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainning_dict = {}\n",
    "for text in test_sample:\n",
    "    trainning_dict[text] = str([themes[i] for i in list(database[text])]).replace(\"'\", '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_instructions = \"\"\"\n",
    "You are a professor of the Humanities (Litterature, Philosophy, Poetry mostly) and as such, you are giving the task to classify texts related to the humanities by themes. You have been provided with texts from which you must exclusively derive its theme(s).\n",
    "\n",
    "You are given the text of a page from a digital book and a fixed list of 33 themes. Your task is to determine which of these themes are relevant to the content of the page.\n",
    "A page can be allocated to more than one theme. However, a page CANNOT be allocated to more than six themes. Only allocate a theme if you are very confident that it is a relevant theme.\n",
    "Remember that it is better to have less relevant themes allocated than many that are irrelevant!\n",
    "Return the allocation in the format: [T<theme_number>, T<theme_number>, ...]\n",
    "Below are the 33 themes along with their guiding questions and descriptions:\n",
    "\n",
    "T1. Consciousness\n",
    "Is consciousness a uniquely human trait and to what extent our individual conscience is shaped by social influences?\n",
    "\n",
    "T2. Desire\n",
    "The relationship between desire, satisfaction, and human nature, examining whether desires can be fulfilled, consciously known, their impact on our wellbeing, and their influence on our behavior and pursuit of truth and goodness.\n",
    "\n",
    "T3. Freedom\n",
    "The relationship between consciousness, personal autonomy, and determinism, examining whether awareness and choice are truly liberating factors in human freedom.\n",
    "\n",
    "T4. Goodness\n",
    "Aspects of moral goodness, examining whether education, perception, intention, and human nature influence ethical behavior and moral development.\n",
    "\n",
    "T5. Identity\n",
    "Facets of personal identity, examining how self-awareness, change, relationships, work, and choices contribute to our understanding of who we are.\n",
    "\n",
    "T6. Justice\n",
    "Dimensions of justice, examining its relationship with freedom, law, conventions, experience, state power, moral choices, and democratic systems.\n",
    "\n",
    "T7. Language\n",
    "The relationship between language and thought, examining whether language serves as a barrier, tool, or mediator in human communication, understanding, and expression.\n",
    "\n",
    "T8. Meaning\n",
    "What has meaning ?\n",
    "\n",
    "T9. Science\n",
    "The fundamental questions raisend by science about knowledge, truth, and human understanding - from the possibility of scientific knowledge about life to the relationship between reason, experience, belief, and certainty.\n",
    "\n",
    "T10. Technology\n",
    "What is the relationship between technological progress, human freedom, and our connection to nature?\n",
    "\n",
    "T11. Truth\n",
    "Dimensions of truth, including its dependence on human perception, methods of verification, relationship with science and politics, and the nature of certainty and doubt.\n",
    "\n",
    "T12. Time\n",
    "Aspects of time, including its relationship with freedom, happiness, destruction, human limitations, knowledge, efficiency, novelty, and leisure.\n",
    "\n",
    "T13. Existence\n",
    "Existence encompasses both action and contemplation, raising questions about how we engage with life's moments and opportunities.\n",
    "\n",
    "T14. Music\n",
    "\n",
    "T15. Imagination\n",
    "Does imagination enrich knowledge and what it means to lack of imagination?\n",
    "\n",
    "T16. The Unconscious\n",
    "The compatibility of the unconscious with freedom, its relationship with self-awareness, and its influence on human expression.\n",
    "\n",
    "T17. Education\n",
    "The relationship between culture, human nature, and personal development, examining whether cultural education liberates us, shapes our character, influences our happiness, and affects our moral development.\n",
    "\n",
    "T18. Body & Mind\n",
    "What difference can be made between the mind and the body?\n",
    "\n",
    "T19. Beauty\n",
    "Dimensions of beauty, from its transformative power on consciousness to its relationship with utility, happiness, and religious experience.\n",
    "\n",
    "T20. Art\n",
    "Aspects of art, including its relationship with understanding, truth, reality, education, language, beauty, meaning, joy and necessity.\n",
    "\n",
    "T21. Love\n",
    "Dimensions of love, including its rationality, universality, self-knowledge, and distinctions from other forms of human connection.\n",
    "\n",
    "T22. Reality\n",
    "The nature of reality and our ability to perceive and understand it, examining aspects like perception, the reliability of appearances, intuition, judgment, and the distinction between dreams and reality.\n",
    "\n",
    "T23. Politics\n",
    "What are the foundations and limits of political authority and human social organization?\n",
    "\n",
    "T24. Work\n",
    "Questions about work, examining its necessity, social impact, virtue, time value, and technical nature.\n",
    "\n",
    "T25. Living Together\n",
    "Questions exploring various aspects of social living, including moral obligations, duty, conflict, responsibility, and the relationship between individual and collective happiness.\n",
    "\n",
    "T26. Philosophy\n",
    "The relationship between philosophy and fundamental concepts like happiness, governance, and religion.\n",
    "\n",
    "T27. Matter\n",
    "Does the mind have access to matter and what is matter?\n",
    "\n",
    "T28. Death\n",
    "What are the fundamental questions about mortality and our ability to comprehend and accept death?\n",
    "\n",
    "T29. Religion\n",
    "Aspects of religion's necessity for humanity, its relationship with reason, and its cultural origins.\n",
    "\n",
    "T30. History\n",
    "Questions about history's nature, examining its scientific status, its relevance to the future, its role in political decision-making, and the agency behind historical events.\n",
    "\n",
    "T31. Thought\n",
    "Thought: its limitations, the nature of ideas, and our ability to comprehend origins.\n",
    "\n",
    "T32. Madness\n",
    "\n",
    "T33. Joy & Happiness\n",
    "Aspects of happiness, including its relationship with truth, consciousness, culture, and well-being, examining whether happiness is achievable, personal, or compatible with the realities of existence.\n",
    "\n",
    "DO NOT provide explanations, only provide the allocation code line.\n",
    "DO NOT provide the title of each theme such as [T7. Language, T5. Identity], only provide the theme code such as [T7, T5].\n",
    "Only allocate a theme if you are very confident that it is relevant.\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "# import re\n",
    "\n",
    "# def clean_text(text: str) -> str:\n",
    "#     # 1) Remove newline characters:\n",
    "#     text = text.replace(\"\\n\", \" \")\n",
    "\n",
    "#     # 2) Remove 4-digit years like 2019, 2020, etc.:\n",
    "#     text = re.sub(r\"\\b\\d{4}\\b\", \"\", text)\n",
    "\n",
    "#     # 3) Reduce multiple spaces to a single space:\n",
    "#     text = re.sub(r\"\\s+\", \" \", text)\n",
    "\n",
    "#     # 4) Strip leading/trailing spaces:\n",
    "#     text = text.strip()\n",
    "\n",
    "#     return text\n",
    "\n",
    "# # Example usage in your loop\n",
    "# output_file = \"data/training_data_1000.jsonl\"\n",
    "\n",
    "# with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "#     for text, themes in trainning_dict.items():\n",
    "#         # Clean the text before using it\n",
    "#         cleaned_text = clean_text(text)\n",
    "\n",
    "#         messages = [\n",
    "#             {\"role\": \"system\", \"content\": system_instructions},\n",
    "#             {\"role\": \"user\", \"content\": cleaned_text},\n",
    "#             {\"role\": \"assistant\", \"content\": themes}\n",
    "#         ]\n",
    "\n",
    "#         json_line = {\"messages\": messages}\n",
    "#         f.write(json.dumps(json_line, ensure_ascii=False) + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num examples: 1000\n",
      "First example:\n",
      "{'role': 'system', 'content': \"\\nYou are a professor of the Humanities (Litterature, Philosophy, Poetry mostly) and as such, you are giving the task to classify texts related to the humanities by themes. You have been provided with texts from which you must exclusively derive its theme(s).\\n\\nYou are given the text of a page from a digital book and a fixed list of 33 themes. Your task is to determine which of these themes are relevant to the content of the page.\\nA page can be allocated to more than one theme. However, a page CANNOT be allocated to more than six themes. Only allocate a theme if you are very confident that it is a relevant theme.\\nRemember that it is better to have less relevant themes allocated than many that are irrelevant!\\nReturn the allocation in the format: [T<theme_number>, T<theme_number>, ...]\\nBelow are the 33 themes along with their guiding questions and descriptions:\\n\\nT1. Consciousness\\nIs consciousness a uniquely human trait and to what extent our individual conscience is shaped by social influences?\\n\\nT2. Desire\\nThe relationship between desire, satisfaction, and human nature, examining whether desires can be fulfilled, consciously known, their impact on our wellbeing, and their influence on our behavior and pursuit of truth and goodness.\\n\\nT3. Freedom\\nThe relationship between consciousness, personal autonomy, and determinism, examining whether awareness and choice are truly liberating factors in human freedom.\\n\\nT4. Goodness\\nAspects of moral goodness, examining whether education, perception, intention, and human nature influence ethical behavior and moral development.\\n\\nT5. Identity\\nFacets of personal identity, examining how self-awareness, change, relationships, work, and choices contribute to our understanding of who we are.\\n\\nT6. Justice\\nDimensions of justice, examining its relationship with freedom, law, conventions, experience, state power, moral choices, and democratic systems.\\n\\nT7. Language\\nThe relationship between language and thought, examining whether language serves as a barrier, tool, or mediator in human communication, understanding, and expression.\\n\\nT8. Meaning\\nWhat has meaning ?\\n\\nT9. Science\\nThe fundamental questions raisend by science about knowledge, truth, and human understanding - from the possibility of scientific knowledge about life to the relationship between reason, experience, belief, and certainty.\\n\\nT10. Technology\\nWhat is the relationship between technological progress, human freedom, and our connection to nature?\\n\\nT11. Truth\\nDimensions of truth, including its dependence on human perception, methods of verification, relationship with science and politics, and the nature of certainty and doubt.\\n\\nT12. Time\\nAspects of time, including its relationship with freedom, happiness, destruction, human limitations, knowledge, efficiency, novelty, and leisure.\\n\\nT13. Existence\\nExistence encompasses both action and contemplation, raising questions about how we engage with life's moments and opportunities.\\n\\nT14. Music\\n\\nT15. Imagination\\nDoes imagination enrich knowledge and what it means to lack of imagination?\\n\\nT16. The Unconscious\\nThe compatibility of the unconscious with freedom, its relationship with self-awareness, and its influence on human expression.\\n\\nT17. Education\\nThe relationship between culture, human nature, and personal development, examining whether cultural education liberates us, shapes our character, influences our happiness, and affects our moral development.\\n\\nT18. Body & Mind\\nWhat difference can be made between the mind and the body?\\n\\nT19. Beauty\\nDimensions of beauty, from its transformative power on consciousness to its relationship with utility, happiness, and religious experience.\\n\\nT20. Art\\nAspects of art, including its relationship with understanding, truth, reality, education, language, beauty, meaning, joy and necessity.\\n\\nT21. Love\\nDimensions of love, including its rationality, universality, self-knowledge, and distinctions from other forms of human connection.\\n\\nT22. Reality\\nThe nature of reality and our ability to perceive and understand it, examining aspects like perception, the reliability of appearances, intuition, judgment, and the distinction between dreams and reality.\\n\\nT23. Politics\\nWhat are the foundations and limits of political authority and human social organization?\\n\\nT24. Work\\nQuestions about work, examining its necessity, social impact, virtue, time value, and technical nature.\\n\\nT25. Living Together\\nQuestions exploring various aspects of social living, including moral obligations, duty, conflict, responsibility, and the relationship between individual and collective happiness.\\n\\nT26. Philosophy\\nThe relationship between philosophy and fundamental concepts like happiness, governance, and religion.\\n\\nT27. Matter\\nDoes the mind have access to matter and what is matter?\\n\\nT28. Death\\nWhat are the fundamental questions about mortality and our ability to comprehend and accept death?\\n\\nT29. Religion\\nAspects of religion's necessity for humanity, its relationship with reason, and its cultural origins.\\n\\nT30. History\\nQuestions about history's nature, examining its scientific status, its relevance to the future, its role in political decision-making, and the agency behind historical events.\\n\\nT31. Thought\\nThought: its limitations, the nature of ideas, and our ability to comprehend origins.\\n\\nT32. Madness\\n\\nT33. Joy & Happiness\\nAspects of happiness, including its relationship with truth, consciousness, culture, and well-being, examining whether happiness is achievable, personal, or compatible with the realities of existence.\\n\\nDO NOT provide explanations, only provide the allocation code line.\\nDO NOT provide the title of each theme such as [T7. Language, T5. Identity], only provide the theme code such as [T7, T5].\\nOnly allocate a theme if you are very confident that it is relevant.\\n    \"}\n",
      "{'role': 'user', 'content': 'Plus tard c’est définitivement maintenant ! Si l’on devait me demander quel a toujours été mon but secret dans l’existence, que pourrais-je répondre sinon que c’est celui de provoquer, au moins une fois par jour un état de furtive éternité ? En effet, s’il est une chose dont je crois pouvoir m’enorgueillir (au regard d’une improbable et vaine postérité), c’est bien celle-ci : savoir, au détour d’une vague pensée, d’un spectacle anodin, d’une embellie soudaine de l’atmosphère et des oiseaux surexcités se pourchassent alors en criaillant hystériquement entre les toits tandis que de bedonnants nuages s’alanguissent dans la savane du ciel d’après-midi…, oui, je me targue, disais-je, de savoir parfaitement faire ceci : m’installer au cœur d’une minime extase fortuite, puis la gonfler comme une bulle de savon enfantine pour la laisser flotter quelques profondes minutes, dans les cas très favorables quelques heures, suspendues au-dessus du va-et-vient des récurrentes urgences (tout en prenant soin, bien entendu, de rester suffisamment discret, car le grand comptable sourcilleux et creveur de bulles, de là où il est, nous surveille et ne badine pas avec ce qu’il estime être le superflu). Bref, savoir maintenir ces instants d’équilibre sur la fine pointe éphémère du présent, c’est là, oui, je le confesse, mon seul intime et ultime art de vivre ! Souffrez donc, chers lecteurs, que je vous livre, afin de nous distraire quelques instants de notre pathétique frénésie d’informations et de fausses nouveautés, et surtout, comme le disait si joliment une commentatrice d’il y a quelques jours, « pour rendre un peu de leur rondeur à nos jours », souffrez donc, gentils amis inconnus, que je vous livre quelques exemples tirés de mon nébuleux livre d’images intimes : Descendre une pente en vélo le long des prairies fleuries d’été et goûter le petit vent frais de la vitesse qui se coulisse dans ma chemise ; nager en suspens au-dessus des gouffres verdâtres d’un lac en admirant la pérennité irréelle des montagnes au-dessus de ma tête ; me glisser dans le courant d’une rivière au moment même où un martin-pêcheur, en rasant la surface, m’évite de justesse ; m’attarder dans une crique bretonne tandis que le vent s’acharne en vain sur les rochers imperturbables et me sentir béni par les embruns ; être assis sur une chaise de paille dans une vieille église et percevoir mon âme qui s’angélise à l’écoute de la voix du ténor dans l’aria du Stabat Mater de Haydn (et si je lève les yeux, les « grotesques » sculptés des voûtes romanes me font des grimaces pour tenter de me ramener au trivial de la vie réelle) ; rencontrer un chat solitaire dans une ruelle du petit matin à Florence, près du jardin Boboli, et comprendre parfaitement - sans toutefois pouvoir l’exprimer - le sens de cette discrète et quasi onirique apparition : lui, l’animal mythique de mon imaginaire, et moi, le héros mythique de ma propre dérisoire saga personnelle, ne sommes que des fantômes passagers, pathétiquement interchangeables, de la grande péripétie qui nous entraîne fatalement tous deux vers l’indifférencié ! Observer le minuscule personnage en bas à droite dans le tableau d’Hobbema, lui-même en train d’observer des enfants qui jouent dans une clairière près d’Haarlem, au XVIIe siècle… et… avoir l’impression, par cette journée de pluie assaillant avec fureur les vitres du musée de Bruxelles - où je me tiens devant l’œuvre accrochée au mur -, que je viens insensiblement d’intégrer une chaîne immémoriale de splendides et furtifs flâneurs (un tantinet espions) qui se donnent la main à travers le temps et anticipent déjà, avec un frisson de plaisir, le regard posé sur eux du futur contemplateur ; découper le matin une reproduction dans un magazine, puis la coller au mur près de la fenêtre, au-dessus de la plante verte, et me féliciter d’avoir ainsi réussi à rehausser la teneur de ma journée à venir ; considérer longuement au crépuscule les jeunes gens fougueux et un peu désordonnés (pour le professionnel que je suis) se disputant le ballon à quelques pas du fleuve impassible ; faire flancher quelques secondes le regard d’une femme (qui n’aura jamais le temps ni le goût de m’aimer en cette vie) dans la lumière tamisée d’un bar vers minuit au milieu des fumées, des rires, et rêver à ce qu’auraient pu être nos amours en d’autres circonstances… ; retrouver dans un vieux carnet et méditer un long moment à son propos, le poème d’Hofmannsthal intitulé Inscription pour une pendule : L’instant vient. Il s’enfuit. Les heures s’en vont, glissent, Révolues, en un souffle, et muées en soupirs ; Mais chacune, en partant, immerge en ton esprit, Afin qu’il y demeure, un éternel présent ! Demeurer enfin quelques longues minutes le matin, derrière la fenêtre de mon bureau (les hirondelles virevoltent dans le ciel gris-bleu) et, à cet instant de relâchement quelque peu oblivieux - juste avant la grande plongée dans l’activisme du monde diurne - comprendre en un éclair, tout de suite résorbé, que : plus tard c’est définitivement maintenant !...'}\n",
      "{'role': 'assistant', 'content': '[T13, T2, T12]'}\n"
     ]
    }
   ],
   "source": [
    "data_path = \"data/training_data_100.jsonl\"\n",
    "\n",
    "# Load the dataset\n",
    "with open(data_path, 'r', encoding='utf-8') as f:\n",
    "    dataset = [json.loads(line) for line in f]\n",
    "\n",
    "# Initial dataset stats\n",
    "print(\"Num examples:\", len(dataset))\n",
    "print(\"First example:\")\n",
    "for message in dataset[0][\"messages\"]:\n",
    "    print(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No errors found\n"
     ]
    }
   ],
   "source": [
    "# Format error checks\n",
    "format_errors = defaultdict(int)\n",
    "\n",
    "for ex in dataset:\n",
    "    if not isinstance(ex, dict):\n",
    "        format_errors[\"data_type\"] += 1\n",
    "        continue\n",
    "\n",
    "    messages = ex.get(\"messages\", None)\n",
    "    if not messages:\n",
    "        format_errors[\"missing_messages_list\"] += 1\n",
    "        continue\n",
    "\n",
    "    for message in messages:\n",
    "        if \"role\" not in message or \"content\" not in message:\n",
    "            format_errors[\"message_missing_key\"] += 1\n",
    "\n",
    "        if any(k not in (\"role\", \"content\", \"name\", \"function_call\", \"weight\") for k in message):\n",
    "            format_errors[\"message_unrecognized_key\"] += 1\n",
    "\n",
    "        if message.get(\"role\", None) not in (\"system\", \"user\", \"assistant\", \"function\"):\n",
    "            format_errors[\"unrecognized_role\"] += 1\n",
    "\n",
    "        content = message.get(\"content\", None)\n",
    "        function_call = message.get(\"function_call\", None)\n",
    "\n",
    "        if (not content and not function_call) or not isinstance(content, str):\n",
    "            format_errors[\"missing_content\"] += 1\n",
    "\n",
    "    if not any(message.get(\"role\", None) == \"assistant\" for message in messages):\n",
    "        format_errors[\"example_missing_assistant_message\"] += 1\n",
    "\n",
    "if format_errors:\n",
    "    print(\"Found errors:\")\n",
    "    for k, v in format_errors.items():\n",
    "        print(f\"{k}: {v}\")\n",
    "else:\n",
    "    print(\"No errors found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "\n",
    "# not exact!\n",
    "# simplified from https://github.com/openai/openai-cookbook/blob/main/examples/How_to_count_tokens_with_tiktoken.ipynb\n",
    "def num_tokens_from_messages(messages, tokens_per_message=3, tokens_per_name=1):\n",
    "    num_tokens = 0\n",
    "    for message in messages:\n",
    "        num_tokens += tokens_per_message\n",
    "        for key, value in message.items():\n",
    "            num_tokens += len(encoding.encode(value))\n",
    "            if key == \"name\":\n",
    "                num_tokens += tokens_per_name\n",
    "    num_tokens += 3\n",
    "    return num_tokens\n",
    "\n",
    "def num_assistant_tokens_from_messages(messages):\n",
    "    num_tokens = 0\n",
    "    for message in messages:\n",
    "        if message[\"role\"] == \"assistant\":\n",
    "            num_tokens += len(encoding.encode(message[\"content\"]))\n",
    "    return num_tokens\n",
    "\n",
    "def print_distribution(values, name):\n",
    "    print(f\"\\n#### Distribution of {name}:\")\n",
    "    print(f\"min / max: {min(values)}, {max(values)}\")\n",
    "    print(f\"mean / median: {np.mean(values)}, {np.median(values)}\")\n",
    "    print(f\"p5 / p95: {np.quantile(values, 0.1)}, {np.quantile(values, 0.9)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num examples missing system message: 0\n",
      "Num examples missing user message: 0\n",
      "\n",
      "#### Distribution of num_messages_per_example:\n",
      "min / max: 3, 3\n",
      "mean / median: 3.0, 3.0\n",
      "p5 / p95: 3.0, 3.0\n",
      "\n",
      "#### Distribution of num_total_tokens_per_example:\n",
      "min / max: 1175, 10055\n",
      "mean / median: 1766.392, 1538.0\n",
      "p5 / p95: 1252.9, 2514.1\n",
      "\n",
      "#### Distribution of num_assistant_tokens_per_example:\n",
      "min / max: 3, 48\n",
      "mean / median: 7.788, 6.0\n",
      "p5 / p95: 3.0, 15.0\n",
      "\n",
      "0 examples may be over the 16,385 token limit, they will be truncated during fine-tuning\n"
     ]
    }
   ],
   "source": [
    "# Warnings and tokens counts\n",
    "n_missing_system = 0\n",
    "n_missing_user = 0\n",
    "n_messages = []\n",
    "convo_lens = []\n",
    "assistant_message_lens = []\n",
    "\n",
    "for ex in dataset:\n",
    "    messages = ex[\"messages\"]\n",
    "    if not any(message[\"role\"] == \"system\" for message in messages):\n",
    "        n_missing_system += 1\n",
    "    if not any(message[\"role\"] == \"user\" for message in messages):\n",
    "        n_missing_user += 1\n",
    "    n_messages.append(len(messages))\n",
    "    convo_lens.append(num_tokens_from_messages(messages))\n",
    "    assistant_message_lens.append(num_assistant_tokens_from_messages(messages))\n",
    "\n",
    "print(\"Num examples missing system message:\", n_missing_system)\n",
    "print(\"Num examples missing user message:\", n_missing_user)\n",
    "print_distribution(n_messages, \"num_messages_per_example\")\n",
    "print_distribution(convo_lens, \"num_total_tokens_per_example\")\n",
    "print_distribution(assistant_message_lens, \"num_assistant_tokens_per_example\")\n",
    "n_too_long = sum(l > 16385 for l in convo_lens)\n",
    "print(f\"\\n{n_too_long} examples may be over the 16,385 token limit, they will be truncated during fine-tuning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset has ~1766392 tokens that will be charged for during training\n",
      "By default, you'll train for 3 epochs on this dataset\n",
      "By default, you'll be charged for ~5299176 tokens\n"
     ]
    }
   ],
   "source": [
    "# Pricing and default n_epochs estimate\n",
    "MAX_TOKENS_PER_EXAMPLE = 16385\n",
    "\n",
    "TARGET_EPOCHS = 3\n",
    "MIN_TARGET_EXAMPLES = 100\n",
    "MAX_TARGET_EXAMPLES = 25000\n",
    "MIN_DEFAULT_EPOCHS = 1\n",
    "MAX_DEFAULT_EPOCHS = 25\n",
    "\n",
    "n_epochs = TARGET_EPOCHS\n",
    "n_train_examples = len(dataset)\n",
    "if n_train_examples * TARGET_EPOCHS < MIN_TARGET_EXAMPLES:\n",
    "    n_epochs = min(MAX_DEFAULT_EPOCHS, MIN_TARGET_EXAMPLES // n_train_examples)\n",
    "elif n_train_examples * TARGET_EPOCHS > MAX_TARGET_EXAMPLES:\n",
    "    n_epochs = max(MIN_DEFAULT_EPOCHS, MAX_TARGET_EXAMPLES // n_train_examples)\n",
    "\n",
    "n_billing_tokens_in_dataset = sum(min(MAX_TOKENS_PER_EXAMPLE, length) for length in convo_lens)\n",
    "print(f\"Dataset has ~{n_billing_tokens_in_dataset} tokens that will be charged for during training\")\n",
    "print(f\"By default, you'll train for {n_epochs} epochs on this dataset\")\n",
    "print(f\"By default, you'll be charged for ~{n_epochs * n_billing_tokens_in_dataset} tokens\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpt-4.0\n",
      "  Total cost: $132.48\n",
      "gpt-4.0-mini\n",
      "  Total cost: $15.90\n",
      "gpt-3.5\n",
      "  Total cost: $42.39\n",
      "davinci-002\n",
      "  Total cost: $31.80\n",
      "babbage-002\n",
      "  Total cost: $2.12\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Pricing per 1,000,000 tokens (updated pricing)\n",
    "PRICING = {\n",
    "    \"gpt-4.0\": 25.000,  # $25.00 per 1,000,000 training tokens\n",
    "    \"gpt-4.0-mini\": 3.000,  # $3.00 per 1,000,000 training tokens\n",
    "    \"gpt-3.5\": 8.000,  # $8.00 per 1,000,000 training tokens\n",
    "    \"davinci-002\": 6.000,  # $6.00 per 1,000,000 training tokens\n",
    "    \"babbage-002\": 0.400  # $0.40 per 1,000,000 training tokens\n",
    "}\n",
    "\n",
    "def calculate_fine_tuning_cost_from_tokens_and_epochs(total_billing_tokens, n_epochs, model_name):\n",
    "    # Cost calculation\n",
    "    cost_per_1m_tokens = PRICING.get(model_name, 0)\n",
    "    total_cost = (total_billing_tokens / 1_000_000) * cost_per_1m_tokens * n_epochs\n",
    "\n",
    "    return {\n",
    "        \"model\": model_name,\n",
    "        \"n_epochs\": n_epochs,\n",
    "        \"total_billing_tokens\": total_billing_tokens,\n",
    "        \"cost\": total_cost\n",
    "    }\n",
    "\n",
    "# Example usage\n",
    "total_billing_tokens = n_billing_tokens_in_dataset  # Replace with the actual total billing tokens\n",
    "n_epochs = 3  # Replace with the actual number of epochs\n",
    "models = [\"gpt-4.0\", \"gpt-4.0-mini\", \"gpt-3.5\", \"davinci-002\", \"babbage-002\"]\n",
    "\n",
    "for model in models:\n",
    "    result = calculate_fine_tuning_cost_from_tokens_and_epochs(total_billing_tokens, n_epochs, model)\n",
    "    print(f\"{result['model']}\")\n",
    "    print(f\"  Total cost: ${result['cost']:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# client.files.list()\n",
    "# client.models.list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 1) Upload the training file\n",
    "\n",
    "# upload_response = client.files.create(\n",
    "#     file=open(\"data/training_data_100.jsonl\", \"rb\"),\n",
    "#     purpose=\"fine-tune\"\n",
    "# )\n",
    "# training_file_id = upload_response.id\n",
    "# print(\"Uploaded file ID:\", training_file_id)\n",
    "\n",
    "# # 'file-Pia7c45jQx5mVEvTYrKHuL'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tune job created. Job ID: ftjob-gq7UKbBfZgtpKgzC9wqsgylG\n"
     ]
    }
   ],
   "source": [
    "# # 2) Create the fine-tuning job\n",
    "\n",
    "# fine_tune_response = client.fine_tuning.jobs.create(\n",
    "#     training_file=\"file-Pia7c45jQx5mVEvTYrKHuL\",\n",
    "#     model=\"gpt-4o-mini-2024-07-18\",\n",
    "#     method={'type': 'supervised',\n",
    "#             'supervised':{\n",
    "#             'hyperparameters': {'n_epochs': 3}}}\n",
    "# )\n",
    "\n",
    "# job_id = fine_tune_response.id\n",
    "# print(\"Fine-tune job created. Job ID:\", job_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job status: succeeded\n",
      "Fine-tuning job succeeded\n"
     ]
    }
   ],
   "source": [
    "# check every 60 sec if job is done\n",
    "\n",
    "while True:\n",
    "    job = client.fine_tuning.jobs.retrieve('ftjob-gq7UKbBfZgtpKgzC9wqsgylG')\n",
    "    print(\"Job status:\", job.status)\n",
    "    if job.status == \"succeeded\":\n",
    "        print(\"Fine-tuning job succeeded\")\n",
    "        break\n",
    "    elif job.status == \"failed\":\n",
    "        print(\"Fine-tuning job failed\")\n",
    "        break\n",
    "    time.sleep(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FineTuningJob(id='ftjob-gq7UKbBfZgtpKgzC9wqsgylG', created_at=1737994944, error=Error(code=None, message=None, param=None), fine_tuned_model='ft:gpt-4o-mini-2024-07-18:fusegpt::AuMp0bXY', finished_at=1737997456, hyperparameters=Hyperparameters(batch_size=2, learning_rate_multiplier=1.8, n_epochs=3), model='gpt-4o-mini-2024-07-18', object='fine_tuning.job', organization_id='org-8uLnwdNry9jphQFFFLaqCG2v', result_files=['file-RX2WGg3Sbhn5L3C9PusFYz'], seed=2100935324, status='succeeded', trained_tokens=5057586, training_file='file-Pia7c45jQx5mVEvTYrKHuL', validation_file=None, estimated_finish=None, integrations=[], method=Method(dpo=None, supervised=MethodSupervised(hyperparameters=MethodSupervisedHyperparameters(batch_size=2, learning_rate_multiplier=1.8, n_epochs=3)), type='supervised'), user_provided_suffix=None)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.fine_tuning.jobs.retrieve('ftjob-gq7UKbBfZgtpKgzC9wqsgylG')\n",
    "\n",
    "# 'ft:gpt-4o-mini-2024-07-18:fusegpt::AuMp0bXY'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lewagon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
