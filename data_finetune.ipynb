{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from make_data import load_dict_from_json\n",
    "from tools import *\n",
    "import json\n",
    "import os\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=os.environ.get(\"FUSE_OPEN_AI_KEY\"))\n",
    "\n",
    "import time\n",
    "\n",
    "import json\n",
    "import tiktoken # for token counting\n",
    "import numpy as np\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "database = load_dict_from_json('data/M0A_train_data.json')\n",
    "# test_sample = select_random_keys(database, 1000, 45)\n",
    "test_sample = select_random_keys(database)\n",
    "\n",
    "trainning_sample = [key for key in database.keys() if key not in test_sample]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "themes = {\n",
    "'Conscience': 'T1',\n",
    "'Desire': 'T2',\n",
    "'Freedom': 'T3',\n",
    "'Goodness': 'T4',\n",
    "'Identity': 'T5',\n",
    "'Justice': 'T6',\n",
    "'Language': 'T7',\n",
    "'Meaning': 'T8',\n",
    "'Science': 'T9',\n",
    "'Technology': 'T10',\n",
    "'Truth': 'T11',\n",
    "'Time': 'T12',\n",
    "'Existence': 'T13',\n",
    "'Music': 'T14',\n",
    "'Imagination': 'T15',\n",
    "'The Unconscious': 'T16',\n",
    "'Education': 'T17',\n",
    "'Body & Mind': 'T18',\n",
    "'Beauty': 'T19',\n",
    "'Art': 'T20',\n",
    "'Love': 'T21',\n",
    "'Reality': 'T22',\n",
    "'Politics': 'T23',\n",
    "'Work': 'T24',\n",
    "'Living Together': 'T25',\n",
    "'Philosophy': 'T26',\n",
    "'Matter': 'T27',\n",
    "'Death': 'T28',\n",
    "'Religion': 'T29',\n",
    "'History': 'T30',\n",
    "'Thought': 'T31',\n",
    "'Madness': 'T32',\n",
    "'Joy & Happiness': 'T33'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainning_dict = {}\n",
    "for text in trainning_sample:\n",
    "    trainning_dict[text] = str([themes[i] for i in list(database[text])]).replace(\"'\", '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_instructions = \"\"\"\n",
    "You are a professor of the Humanities (Litterature, Philosophy, Poetry mostly) and as such, you are giving the task to classify texts related to the humanities by themes. You have been provided with texts from which you must exclusively derive its theme(s).\n",
    "\n",
    "You are given the text of a page from a digital book and a fixed list of 33 themes. Your task is to determine which of these themes are relevant to the content of the page.\n",
    "A page can be allocated to more than one theme. However, a page CANNOT be allocated to more than six themes. Only allocate a theme if you are very confident that it is a relevant theme.\n",
    "Remember that it is better to have less relevant themes allocated than many that are irrelevant!\n",
    "Return the allocation in the format: [T<theme_number>, T<theme_number>, ...]\n",
    "Below are the 33 themes along with their guiding questions and descriptions:\n",
    "\n",
    "T1. Consciousness\n",
    "Is consciousness a uniquely human trait and to what extent our individual conscience is shaped by social influences?\n",
    "\n",
    "T2. Desire\n",
    "The relationship between desire, satisfaction, and human nature, examining whether desires can be fulfilled, consciously known, their impact on our wellbeing, and their influence on our behavior and pursuit of truth and goodness.\n",
    "\n",
    "T3. Freedom\n",
    "The relationship between consciousness, personal autonomy, and determinism, examining whether awareness and choice are truly liberating factors in human freedom.\n",
    "\n",
    "T4. Goodness\n",
    "Aspects of moral goodness, examining whether education, perception, intention, and human nature influence ethical behavior and moral development.\n",
    "\n",
    "T5. Identity\n",
    "Facets of personal identity, examining how self-awareness, change, relationships, work, and choices contribute to our understanding of who we are.\n",
    "\n",
    "T6. Justice\n",
    "Dimensions of justice, examining its relationship with freedom, law, conventions, experience, state power, moral choices, and democratic systems.\n",
    "\n",
    "T7. Language\n",
    "The relationship between language and thought, examining whether language serves as a barrier, tool, or mediator in human communication, understanding, and expression.\n",
    "\n",
    "T8. Meaning\n",
    "What has meaning ?\n",
    "\n",
    "T9. Science\n",
    "The fundamental questions raisend by science about knowledge, truth, and human understanding - from the possibility of scientific knowledge about life to the relationship between reason, experience, belief, and certainty.\n",
    "\n",
    "T10. Technology\n",
    "What is the relationship between technological progress, human freedom, and our connection to nature?\n",
    "\n",
    "T11. Truth\n",
    "Dimensions of truth, including its dependence on human perception, methods of verification, relationship with science and politics, and the nature of certainty and doubt.\n",
    "\n",
    "T12. Time\n",
    "Aspects of time, including its relationship with freedom, happiness, destruction, human limitations, knowledge, efficiency, novelty, and leisure.\n",
    "\n",
    "T13. Existence\n",
    "Existence encompasses both action and contemplation, raising questions about how we engage with life's moments and opportunities.\n",
    "\n",
    "T14. Music\n",
    "\n",
    "T15. Imagination\n",
    "Does imagination enrich knowledge and what it means to lack of imagination?\n",
    "\n",
    "T16. The Unconscious\n",
    "The compatibility of the unconscious with freedom, its relationship with self-awareness, and its influence on human expression.\n",
    "\n",
    "T17. Education\n",
    "The relationship between culture, human nature, and personal development, examining whether cultural education liberates us, shapes our character, influences our happiness, and affects our moral development.\n",
    "\n",
    "T18. Body & Mind\n",
    "What difference can be made between the mind and the body?\n",
    "\n",
    "T19. Beauty\n",
    "Dimensions of beauty, from its transformative power on consciousness to its relationship with utility, happiness, and religious experience.\n",
    "\n",
    "T20. Art\n",
    "Aspects of art, including its relationship with understanding, truth, reality, education, language, beauty, meaning, joy and necessity.\n",
    "\n",
    "T21. Love\n",
    "Dimensions of love, including its rationality, universality, self-knowledge, and distinctions from other forms of human connection.\n",
    "\n",
    "T22. Reality\n",
    "The nature of reality and our ability to perceive and understand it, examining aspects like perception, the reliability of appearances, intuition, judgment, and the distinction between dreams and reality.\n",
    "\n",
    "T23. Politics\n",
    "What are the foundations and limits of political authority and human social organization?\n",
    "\n",
    "T24. Work\n",
    "Questions about work, examining its necessity, social impact, virtue, time value, and technical nature.\n",
    "\n",
    "T25. Living Together\n",
    "Questions exploring various aspects of social living, including moral obligations, duty, conflict, responsibility, and the relationship between individual and collective happiness.\n",
    "\n",
    "T26. Philosophy\n",
    "The relationship between philosophy and fundamental concepts like happiness, governance, and religion.\n",
    "\n",
    "T27. Matter\n",
    "Does the mind have access to matter and what is matter?\n",
    "\n",
    "T28. Death\n",
    "What are the fundamental questions about mortality and our ability to comprehend and accept death?\n",
    "\n",
    "T29. Religion\n",
    "Aspects of religion's necessity for humanity, its relationship with reason, and its cultural origins.\n",
    "\n",
    "T30. History\n",
    "Questions about history's nature, examining its scientific status, its relevance to the future, its role in political decision-making, and the agency behind historical events.\n",
    "\n",
    "T31. Thought\n",
    "Thought: its limitations, the nature of ideas, and our ability to comprehend origins.\n",
    "\n",
    "T32. Madness\n",
    "\n",
    "T33. Joy & Happiness\n",
    "Aspects of happiness, including its relationship with truth, consciousness, culture, and well-being, examining whether happiness is achievable, personal, or compatible with the realities of existence.\n",
    "\n",
    "DO NOT provide explanations, only provide the allocation code line.\n",
    "DO NOT provide the title of each theme such as [T7. Language, T5. Identity], only provide the theme code such as [T7, T5].\n",
    "Only allocate a theme if you are very confident that it is relevant.\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "# import re\n",
    "\n",
    "# def clean_text(text: str) -> str:\n",
    "#     # 1) Remove newline characters:\n",
    "#     text = text.replace(\"\\n\", \" \")\n",
    "\n",
    "#     # 2) Remove 4-digit years like 2019, 2020, etc.:\n",
    "#     text = re.sub(r\"\\b\\d{4}\\b\", \"\", text)\n",
    "\n",
    "#     # 3) Reduce multiple spaces to a single space:\n",
    "#     text = re.sub(r\"\\s+\", \" \", text)\n",
    "\n",
    "#     # 4) Strip leading/trailing spaces:\n",
    "#     text = text.strip()\n",
    "\n",
    "#     return text\n",
    "\n",
    "# # Example usage in your loop\n",
    "# output_file = \"data/_FINE_TUNE_training_data.jsonl\"\n",
    "\n",
    "# with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "#     for text, themes in trainning_dict.items():\n",
    "#         # Clean the text before using it\n",
    "#         cleaned_text = clean_text(text)\n",
    "\n",
    "#         messages = [\n",
    "#             {\"role\": \"system\", \"content\": system_instructions},\n",
    "#             {\"role\": \"user\", \"content\": cleaned_text},\n",
    "#             {\"role\": \"assistant\", \"content\": themes}\n",
    "#         ]\n",
    "\n",
    "#         json_line = {\"messages\": messages}\n",
    "#         f.write(json.dumps(json_line, ensure_ascii=False) + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num examples: 3539\n",
      "First example:\n",
      "{'role': 'system', 'content': \"\\nYou are a professor of the Humanities (Litterature, Philosophy, Poetry mostly) and as such, you are giving the task to classify texts related to the humanities by themes. You have been provided with texts from which you must exclusively derive its theme(s).\\n\\nYou are given the text of a page from a digital book and a fixed list of 33 themes. Your task is to determine which of these themes are relevant to the content of the page.\\nA page can be allocated to more than one theme. However, a page CANNOT be allocated to more than six themes. Only allocate a theme if you are very confident that it is a relevant theme.\\nRemember that it is better to have less relevant themes allocated than many that are irrelevant!\\nReturn the allocation in the format: [T<theme_number>, T<theme_number>, ...]\\nBelow are the 33 themes along with their guiding questions and descriptions:\\n\\nT1. Consciousness\\nIs consciousness a uniquely human trait and to what extent our individual conscience is shaped by social influences?\\n\\nT2. Desire\\nThe relationship between desire, satisfaction, and human nature, examining whether desires can be fulfilled, consciously known, their impact on our wellbeing, and their influence on our behavior and pursuit of truth and goodness.\\n\\nT3. Freedom\\nThe relationship between consciousness, personal autonomy, and determinism, examining whether awareness and choice are truly liberating factors in human freedom.\\n\\nT4. Goodness\\nAspects of moral goodness, examining whether education, perception, intention, and human nature influence ethical behavior and moral development.\\n\\nT5. Identity\\nFacets of personal identity, examining how self-awareness, change, relationships, work, and choices contribute to our understanding of who we are.\\n\\nT6. Justice\\nDimensions of justice, examining its relationship with freedom, law, conventions, experience, state power, moral choices, and democratic systems.\\n\\nT7. Language\\nThe relationship between language and thought, examining whether language serves as a barrier, tool, or mediator in human communication, understanding, and expression.\\n\\nT8. Meaning\\nWhat has meaning ?\\n\\nT9. Science\\nThe fundamental questions raisend by science about knowledge, truth, and human understanding - from the possibility of scientific knowledge about life to the relationship between reason, experience, belief, and certainty.\\n\\nT10. Technology\\nWhat is the relationship between technological progress, human freedom, and our connection to nature?\\n\\nT11. Truth\\nDimensions of truth, including its dependence on human perception, methods of verification, relationship with science and politics, and the nature of certainty and doubt.\\n\\nT12. Time\\nAspects of time, including its relationship with freedom, happiness, destruction, human limitations, knowledge, efficiency, novelty, and leisure.\\n\\nT13. Existence\\nExistence encompasses both action and contemplation, raising questions about how we engage with life's moments and opportunities.\\n\\nT14. Music\\n\\nT15. Imagination\\nDoes imagination enrich knowledge and what it means to lack of imagination?\\n\\nT16. The Unconscious\\nThe compatibility of the unconscious with freedom, its relationship with self-awareness, and its influence on human expression.\\n\\nT17. Education\\nThe relationship between culture, human nature, and personal development, examining whether cultural education liberates us, shapes our character, influences our happiness, and affects our moral development.\\n\\nT18. Body & Mind\\nWhat difference can be made between the mind and the body?\\n\\nT19. Beauty\\nDimensions of beauty, from its transformative power on consciousness to its relationship with utility, happiness, and religious experience.\\n\\nT20. Art\\nAspects of art, including its relationship with understanding, truth, reality, education, language, beauty, meaning, joy and necessity.\\n\\nT21. Love\\nDimensions of love, including its rationality, universality, self-knowledge, and distinctions from other forms of human connection.\\n\\nT22. Reality\\nThe nature of reality and our ability to perceive and understand it, examining aspects like perception, the reliability of appearances, intuition, judgment, and the distinction between dreams and reality.\\n\\nT23. Politics\\nWhat are the foundations and limits of political authority and human social organization?\\n\\nT24. Work\\nQuestions about work, examining its necessity, social impact, virtue, time value, and technical nature.\\n\\nT25. Living Together\\nQuestions exploring various aspects of social living, including moral obligations, duty, conflict, responsibility, and the relationship between individual and collective happiness.\\n\\nT26. Philosophy\\nThe relationship between philosophy and fundamental concepts like happiness, governance, and religion.\\n\\nT27. Matter\\nDoes the mind have access to matter and what is matter?\\n\\nT28. Death\\nWhat are the fundamental questions about mortality and our ability to comprehend and accept death?\\n\\nT29. Religion\\nAspects of religion's necessity for humanity, its relationship with reason, and its cultural origins.\\n\\nT30. History\\nQuestions about history's nature, examining its scientific status, its relevance to the future, its role in political decision-making, and the agency behind historical events.\\n\\nT31. Thought\\nThought: its limitations, the nature of ideas, and our ability to comprehend origins.\\n\\nT32. Madness\\n\\nT33. Joy & Happiness\\nAspects of happiness, including its relationship with truth, consciousness, culture, and well-being, examining whether happiness is achievable, personal, or compatible with the realities of existence.\\n\\nDO NOT provide explanations, only provide the allocation code line.\\nDO NOT provide the title of each theme such as [T7. Language, T5. Identity], only provide the theme code such as [T7, T5].\\nOnly allocate a theme if you are very confident that it is relevant.\\n    \"}\n",
      "{'role': 'user', 'content': '14 SIGNIFICATION DE LA FOLIE DANS L’HISTOIRE DE L’HUMANITÉ. Si, malgré ce formidable joug de la moralité des mœurs, sous lequel toutes les communautés humaines ont vécu, si — durant des millénaires avant notre calendrier et dans celui-ci tout au long du temps jusqu’à nos jours (nous habitons nous-mêmes, dans un petit monde d’exception et en quelque sorte dans la zone mauvaise) — des pensées, des appréciations et des tendances nouvelles et divergentes ont surgi toujours de nouveau, ce ne fut cependant que parce qu’elles étaient sous un terrible sauf-conduit : presque partout c’est la folie qui aplanit le chemin de la pensée novatrice, qui rompt le ban d’une coutume, d’une superstition respectée. [...] Avançons encore d’un pas : tous ces hommes supérieurs poussés irrésistiblement à briser le joug d’une moralité quelconque et à proclamer des lois nouvelles n’avaient rien d’autre à faire, s’ils n’étaient pas véritablement fous, que de le devenir ou de simuler la folie — et c’est valable pour tous les novateurs dans tous les domaines, et non seulement pour ceux des institutions sacerdotales et politiques : — même le novateur du mètre poétique dut se faire accréditer par la folie. (Jusqu’à des époques beaucoup plus tempérées, la folie resta comme une espèce de convention chez les poètes) [...]'}\n",
      "{'role': 'assistant', 'content': '[T31, T32, T5, T12]'}\n"
     ]
    }
   ],
   "source": [
    "data_path = \"data/_FINE_TUNE_training_data.jsonl\"\n",
    "\n",
    "# Load the dataset\n",
    "with open(data_path, 'r', encoding='utf-8') as f:\n",
    "    dataset = [json.loads(line) for line in f]\n",
    "\n",
    "# Initial dataset stats\n",
    "print(\"Num examples:\", len(dataset))\n",
    "print(\"First example:\")\n",
    "for message in dataset[1][\"messages\"]:\n",
    "    print(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No errors found\n"
     ]
    }
   ],
   "source": [
    "# Format error checks\n",
    "format_errors = defaultdict(int)\n",
    "\n",
    "for ex in dataset:\n",
    "    if not isinstance(ex, dict):\n",
    "        format_errors[\"data_type\"] += 1\n",
    "        continue\n",
    "\n",
    "    messages = ex.get(\"messages\", None)\n",
    "    if not messages:\n",
    "        format_errors[\"missing_messages_list\"] += 1\n",
    "        continue\n",
    "\n",
    "    for idx, message in enumerate(messages):\n",
    "        if \"role\" not in message or \"content\" not in message:\n",
    "            format_errors[\"message_missing_key\"] += 1\n",
    "\n",
    "\n",
    "        if any(k not in (\"role\", \"content\", \"name\", \"function_call\", \"weight\") for k in message):\n",
    "            format_errors[\"message_unrecognized_key\"] += 1\n",
    "\n",
    "        if message.get(\"role\", None) not in (\"system\", \"user\", \"assistant\", \"function\"):\n",
    "            format_errors[\"unrecognized_role\"] += 1\n",
    "\n",
    "        content = message.get(\"content\", None)\n",
    "        function_call = message.get(\"function_call\", None)\n",
    "\n",
    "        if (not content and not function_call) or not isinstance(content, str):\n",
    "            format_errors[\"missing_content\"] += 1\n",
    "\n",
    "    if not any(message.get(\"role\", None) == \"assistant\" for message in messages):\n",
    "        format_errors[\"example_missing_assistant_message\"] += 1\n",
    "\n",
    "if format_errors:\n",
    "    print(\"Found errors:\")\n",
    "    for k, v in format_errors.items():\n",
    "        print(f\"{k}: {v}\")\n",
    "else:\n",
    "    print(\"No errors found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "\n",
    "# not exact!\n",
    "# simplified from https://github.com/openai/openai-cookbook/blob/main/examples/How_to_count_tokens_with_tiktoken.ipynb\n",
    "def num_tokens_from_messages(messages, tokens_per_message=3, tokens_per_name=1):\n",
    "    num_tokens = 0\n",
    "    for message in messages:\n",
    "        num_tokens += tokens_per_message\n",
    "        for key, value in message.items():\n",
    "            num_tokens += len(encoding.encode(value))\n",
    "            if key == \"name\":\n",
    "                num_tokens += tokens_per_name\n",
    "    num_tokens += 3\n",
    "    return num_tokens\n",
    "\n",
    "def num_assistant_tokens_from_messages(messages):\n",
    "    num_tokens = 0\n",
    "    for message in messages:\n",
    "        if message[\"role\"] == \"assistant\":\n",
    "            num_tokens += len(encoding.encode(message[\"content\"]))\n",
    "    return num_tokens\n",
    "\n",
    "def print_distribution(values, name):\n",
    "    print(f\"\\n#### Distribution of {name}:\")\n",
    "    print(f\"min / max: {min(values)}, {max(values)}\")\n",
    "    print(f\"mean / median: {np.mean(values)}, {np.median(values)}\")\n",
    "    print(f\"p5 / p95: {np.quantile(values, 0.1)}, {np.quantile(values, 0.9)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num examples missing system message: 0\n",
      "Num examples missing user message: 0\n",
      "\n",
      "#### Distribution of num_messages_per_example:\n",
      "min / max: 3, 3\n",
      "mean / median: 3.0, 3.0\n",
      "p5 / p95: 3.0, 3.0\n",
      "\n",
      "#### Distribution of num_total_tokens_per_example:\n",
      "min / max: 1165, 10055\n",
      "mean / median: 1754.4772534614299, 1545.0\n",
      "p5 / p95: 1260.8, 2490.2000000000003\n",
      "\n",
      "#### Distribution of num_assistant_tokens_per_example:\n",
      "min / max: 3, 48\n",
      "mean / median: 7.8284826222096635, 6.0\n",
      "p5 / p95: 3.0, 15.0\n",
      "\n",
      "0 examples may be over the 16,385 token limit, they will be truncated during fine-tuning\n"
     ]
    }
   ],
   "source": [
    "# Warnings and tokens counts\n",
    "n_missing_system = 0\n",
    "n_missing_user = 0\n",
    "n_messages = []\n",
    "convo_lens = []\n",
    "assistant_message_lens = []\n",
    "\n",
    "for ex in dataset:\n",
    "    messages = ex[\"messages\"]\n",
    "    if not any(message[\"role\"] == \"system\" for message in messages):\n",
    "        n_missing_system += 1\n",
    "    if not any(message[\"role\"] == \"user\" for message in messages):\n",
    "        n_missing_user += 1\n",
    "    n_messages.append(len(messages))\n",
    "    convo_lens.append(num_tokens_from_messages(messages))\n",
    "    assistant_message_lens.append(num_assistant_tokens_from_messages(messages))\n",
    "\n",
    "print(\"Num examples missing system message:\", n_missing_system)\n",
    "print(\"Num examples missing user message:\", n_missing_user)\n",
    "print_distribution(n_messages, \"num_messages_per_example\")\n",
    "print_distribution(convo_lens, \"num_total_tokens_per_example\")\n",
    "print_distribution(assistant_message_lens, \"num_assistant_tokens_per_example\")\n",
    "n_too_long = sum(l > 16385 for l in convo_lens)\n",
    "print(f\"\\n{n_too_long} examples may be over the 16,385 token limit, they will be truncated during fine-tuning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset has ~6209095 tokens that will be charged for during training\n",
      "By default, you'll train for 3 epochs on this dataset\n",
      "By default, you'll be charged for ~18627285 tokens\n"
     ]
    }
   ],
   "source": [
    "# Pricing and default n_epochs estimate\n",
    "MAX_TOKENS_PER_EXAMPLE = 16385\n",
    "\n",
    "TARGET_EPOCHS = 3\n",
    "MIN_TARGET_EXAMPLES = 100\n",
    "MAX_TARGET_EXAMPLES = 25000\n",
    "MIN_DEFAULT_EPOCHS = 1\n",
    "MAX_DEFAULT_EPOCHS = 25\n",
    "\n",
    "n_epochs = TARGET_EPOCHS\n",
    "n_train_examples = len(dataset)\n",
    "if n_train_examples * TARGET_EPOCHS < MIN_TARGET_EXAMPLES:\n",
    "    n_epochs = min(MAX_DEFAULT_EPOCHS, MIN_TARGET_EXAMPLES // n_train_examples)\n",
    "elif n_train_examples * TARGET_EPOCHS > MAX_TARGET_EXAMPLES:\n",
    "    n_epochs = max(MIN_DEFAULT_EPOCHS, MAX_TARGET_EXAMPLES // n_train_examples)\n",
    "\n",
    "n_billing_tokens_in_dataset = sum(min(MAX_TOKENS_PER_EXAMPLE, length) for length in convo_lens)\n",
    "print(f\"Dataset has ~{n_billing_tokens_in_dataset} tokens that will be charged for during training\")\n",
    "print(f\"By default, you'll train for {n_epochs} epochs on this dataset\")\n",
    "print(f\"By default, you'll be charged for ~{n_epochs * n_billing_tokens_in_dataset} tokens\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpt-4.0\n",
      "  Total cost: $465.68\n",
      "gpt-4.0-mini\n",
      "  Total cost: $55.88\n",
      "gpt-3.5\n",
      "  Total cost: $149.02\n",
      "davinci-002\n",
      "  Total cost: $111.76\n",
      "babbage-002\n",
      "  Total cost: $7.45\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Pricing per 1,000,000 tokens (updated pricing)\n",
    "PRICING = {\n",
    "    \"gpt-4.0\": 25.000,  # $25.00 per 1,000,000 training tokens\n",
    "    \"gpt-4.0-mini\": 3.000,  # $3.00 per 1,000,000 training tokens\n",
    "    \"gpt-3.5\": 8.000,  # $8.00 per 1,000,000 training tokens\n",
    "    \"davinci-002\": 6.000,  # $6.00 per 1,000,000 training tokens\n",
    "    \"babbage-002\": 0.400  # $0.40 per 1,000,000 training tokens\n",
    "}\n",
    "\n",
    "def calculate_fine_tuning_cost_from_tokens_and_epochs(total_billing_tokens, n_epochs, model_name):\n",
    "    # Cost calculation\n",
    "    cost_per_1m_tokens = PRICING.get(model_name, 0)\n",
    "    total_cost = (total_billing_tokens / 1_000_000) * cost_per_1m_tokens * n_epochs\n",
    "\n",
    "    return {\n",
    "        \"model\": model_name,\n",
    "        \"n_epochs\": n_epochs,\n",
    "        \"total_billing_tokens\": total_billing_tokens,\n",
    "        \"cost\": total_cost\n",
    "    }\n",
    "\n",
    "# Example usage\n",
    "total_billing_tokens = n_billing_tokens_in_dataset  # Replace with the actual total billing tokens\n",
    "n_epochs = 3  # Replace with the actual number of epochs\n",
    "models = [\"gpt-4.0\", \"gpt-4.0-mini\", \"gpt-3.5\", \"davinci-002\", \"babbage-002\"]\n",
    "\n",
    "for model in models:\n",
    "    result = calculate_fine_tuning_cost_from_tokens_and_epochs(total_billing_tokens, n_epochs, model)\n",
    "    print(f\"{result['model']}\")\n",
    "    print(f\"  Total cost: ${result['cost']:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SyncPage[Model](data=[Model(id='gpt-4.5-preview', created=1740623059, object='model', owned_by='system'), Model(id='gpt-4.5-preview-2025-02-27', created=1740623304, object='model', owned_by='system'), Model(id='gpt-4o-mini-audio-preview-2024-12-17', created=1734115920, object='model', owned_by='system'), Model(id='dall-e-3', created=1698785189, object='model', owned_by='system'), Model(id='dall-e-2', created=1698798177, object='model', owned_by='system'), Model(id='gpt-4o-audio-preview-2024-10-01', created=1727389042, object='model', owned_by='system'), Model(id='gpt-4o-audio-preview', created=1727460443, object='model', owned_by='system'), Model(id='gpt-4o-mini-realtime-preview-2024-12-17', created=1734112601, object='model', owned_by='system'), Model(id='gpt-4o-mini-realtime-preview', created=1734387380, object='model', owned_by='system'), Model(id='o1-mini-2024-09-12', created=1725648979, object='model', owned_by='system'), Model(id='o1-mini', created=1725649008, object='model', owned_by='system'), Model(id='omni-moderation-latest', created=1731689265, object='model', owned_by='system'), Model(id='gpt-4o-mini-audio-preview', created=1734387424, object='model', owned_by='system'), Model(id='omni-moderation-2024-09-26', created=1732734466, object='model', owned_by='system'), Model(id='whisper-1', created=1677532384, object='model', owned_by='openai-internal'), Model(id='gpt-4o-realtime-preview-2024-10-01', created=1727131766, object='model', owned_by='system'), Model(id='babbage-002', created=1692634615, object='model', owned_by='system'), Model(id='gpt-4-turbo-preview', created=1706037777, object='model', owned_by='system'), Model(id='chatgpt-4o-latest', created=1723515131, object='model', owned_by='system'), Model(id='tts-1-hd-1106', created=1699053533, object='model', owned_by='system'), Model(id='text-embedding-3-large', created=1705953180, object='model', owned_by='system'), Model(id='gpt-4-0125-preview', created=1706037612, object='model', owned_by='system'), Model(id='gpt-4o-audio-preview-2024-12-17', created=1734034239, object='model', owned_by='system'), Model(id='gpt-4', created=1687882411, object='model', owned_by='openai'), Model(id='gpt-4o-2024-05-13', created=1715368132, object='model', owned_by='system'), Model(id='gpt-4o-mini', created=1721172741, object='model', owned_by='system'), Model(id='gpt-4o-mini-2024-07-18', created=1721172717, object='model', owned_by='system'), Model(id='tts-1-hd', created=1699046015, object='model', owned_by='system'), Model(id='o1-preview', created=1725648897, object='model', owned_by='system'), Model(id='o1-preview-2024-09-12', created=1725648865, object='model', owned_by='system'), Model(id='gpt-4o-2024-11-20', created=1739331543, object='model', owned_by='system'), Model(id='gpt-3.5-turbo-instruct-0914', created=1694122472, object='model', owned_by='system'), Model(id='tts-1', created=1681940951, object='model', owned_by='openai-internal'), Model(id='tts-1-1106', created=1699053241, object='model', owned_by='system'), Model(id='o3-mini', created=1737146383, object='model', owned_by='system'), Model(id='o3-mini-2025-01-31', created=1738010200, object='model', owned_by='system'), Model(id='davinci-002', created=1692634301, object='model', owned_by='system'), Model(id='gpt-3.5-turbo-1106', created=1698959748, object='model', owned_by='system'), Model(id='gpt-4-turbo', created=1712361441, object='model', owned_by='system'), Model(id='gpt-3.5-turbo-instruct', created=1692901427, object='model', owned_by='system'), Model(id='o1', created=1734375816, object='model', owned_by='system'), Model(id='gpt-4o-2024-08-06', created=1722814719, object='model', owned_by='system'), Model(id='gpt-3.5-turbo-0125', created=1706048358, object='model', owned_by='system'), Model(id='gpt-4o-realtime-preview-2024-12-17', created=1733945430, object='model', owned_by='system'), Model(id='gpt-3.5-turbo', created=1677610602, object='model', owned_by='openai'), Model(id='gpt-4-turbo-2024-04-09', created=1712601677, object='model', owned_by='system'), Model(id='gpt-4o-realtime-preview', created=1727659998, object='model', owned_by='system'), Model(id='gpt-3.5-turbo-16k', created=1683758102, object='model', owned_by='openai-internal'), Model(id='gpt-4o', created=1715367049, object='model', owned_by='system'), Model(id='text-embedding-3-small', created=1705948997, object='model', owned_by='system'), Model(id='gpt-4-1106-preview', created=1698957206, object='model', owned_by='system'), Model(id='text-embedding-ada-002', created=1671217299, object='model', owned_by='openai-internal'), Model(id='gpt-4-0613', created=1686588896, object='model', owned_by='openai'), Model(id='o1-2024-12-17', created=1734326976, object='model', owned_by='system'), Model(id='ft:gpt-4o-2024-08-06:fusegpt::ArnqePUx:ckpt-step-100', created=1737386364, object='model', owned_by='fusegpt'), Model(id='ft:gpt-4o-2024-08-06:fusegpt::Arnqe6S3:ckpt-step-200', created=1737386364, object='model', owned_by='fusegpt'), Model(id='ft:gpt-4o-2024-08-06:fusegpt::ArnqeN0p', created=1737386364, object='model', owned_by='fusegpt'), Model(id='ft:gpt-4o-2024-08-06:fusegpt::ArnvW0oe:ckpt-step-100', created=1737386666, object='model', owned_by='fusegpt'), Model(id='ft:gpt-4o-2024-08-06:fusegpt::ArnvWJ8e:ckpt-step-200', created=1737386666, object='model', owned_by='fusegpt'), Model(id='ft:gpt-4o-2024-08-06:fusegpt::ArnvWWD1', created=1737386666, object='model', owned_by='fusegpt'), Model(id='ft:gpt-4o-mini-2024-07-18:fusegpt::AuMozw6h:ckpt-step-500', created=1737997458, object='model', owned_by='fusegpt'), Model(id='ft:gpt-4o-mini-2024-07-18:fusegpt::AuMp0XKD:ckpt-step-1000', created=1737997458, object='model', owned_by='fusegpt'), Model(id='ft:gpt-4o-mini-2024-07-18:fusegpt::AuMp0bXY', created=1737997458, object='model', owned_by='fusegpt'), Model(id='ft:gpt-4o-2024-08-06:fusegpt::Asv8Tcnl:ckpt-step-100', created=1737652705, object='model', owned_by='fusegpt'), Model(id='ft:gpt-4o-2024-08-06:fusegpt::Asv8TwXO:ckpt-step-200', created=1737652705, object='model', owned_by='fusegpt'), Model(id='ft:gpt-4o-2024-08-06:fusegpt::Asv8UYkq', created=1737652706, object='model', owned_by='fusegpt')], object='list')\n"
     ]
    }
   ],
   "source": [
    "client.files.list()\n",
    "client.models.list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded file ID: file-N9GkRM1LB2hg6u7a2JaZdR\n"
     ]
    }
   ],
   "source": [
    "# 1) Upload the training file\n",
    "\n",
    "upload_response = client.files.create(\n",
    "    file=open(\"data/_FINE_TUNE_training_data.jsonl\", \"rb\"),\n",
    "    purpose=\"fine-tune\"\n",
    ")\n",
    "training_file_id = upload_response.id\n",
    "print(\"Uploaded file ID:\", training_file_id)\n",
    "\n",
    "# file-N9GkRM1LB2hg6u7a2JaZdR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tune job created. Job ID: ftjob-wkUXo5zfBeJgQsmf9wYuAlf3\n"
     ]
    }
   ],
   "source": [
    "# 2) Create the fine-tuning job\n",
    "\n",
    "fine_tune_response = client.fine_tuning.jobs.create(\n",
    "    training_file=\"file-N9GkRM1LB2hg6u7a2JaZdR\",\n",
    "    model=\"gpt-4o-mini-2024-07-18\",\n",
    "    method={'type': 'supervised',\n",
    "            'supervised':{\n",
    "            'hyperparameters': {'n_epochs': 3}}}\n",
    ")\n",
    "\n",
    "job_id = fine_tune_response.id\n",
    "print(\"Fine-tune job created. Job ID:\", job_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job status: succeeded\n",
      "Fine-tuning job succeeded\n"
     ]
    }
   ],
   "source": [
    "# check every 60 sec if job is done\n",
    "\n",
    "while True:\n",
    "    job = client.fine_tuning.jobs.retrieve('ftjob-wkUXo5zfBeJgQsmf9wYuAlf3')\n",
    "    print(\"Job status:\", job.status)\n",
    "    if job.status == \"succeeded\":\n",
    "        print(\"Fine-tuning job succeeded\")\n",
    "        break\n",
    "    elif job.status == \"failed\":\n",
    "        print(\"Fine-tuning job failed\")\n",
    "        break\n",
    "    time.sleep(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FineTuningJob(id='ftjob-wkUXo5zfBeJgQsmf9wYuAlf3', created_at=1741603858, error=Error(code=None, message=None, param=None), fine_tuned_model='ft:gpt-4o-mini-2024-07-18:fusegpt::B9WQyjDX', finished_at=1741609325, hyperparameters=Hyperparameters(batch_size=7, learning_rate_multiplier=1.8, n_epochs=3), model='gpt-4o-mini-2024-07-18', object='fine_tuning.job', organization_id='org-8uLnwdNry9jphQFFFLaqCG2v', result_files=['file-XtKp5RnA5aM5wBNh1cRFfR'], seed=1986352788, status='succeeded', trained_tokens=17791959, training_file='file-N9GkRM1LB2hg6u7a2JaZdR', validation_file=None, estimated_finish=None, integrations=[], method=Method(dpo=None, supervised=MethodSupervised(hyperparameters=MethodSupervisedHyperparameters(batch_size=7, learning_rate_multiplier=1.8, n_epochs=3)), type='supervised'), user_provided_suffix=None, metadata=None)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.fine_tuning.jobs.retrieve('ftjob-wkUXo5zfBeJgQsmf9wYuAlf3')\n",
    "\n",
    "# ft:gpt-4o-mini-2024-07-18:fusegpt::B9WQyjDX"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lewagon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
